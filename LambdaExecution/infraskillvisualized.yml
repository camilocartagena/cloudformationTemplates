AWSTemplateFormatVersion: "2010-09-09"
Resources:
  # S3 Bucket for Excel Upload
  ExcelUploadBucket:
    Type: AWS::S3::Bucket
    Properties:
      BucketName: excel-up-cartagena
      PublicAccessBlockConfiguration:
        BlockPublicAcls: true
        BlockPublicPolicy: true
        IgnorePublicAcls: true
        RestrictPublicBuckets: true

  # S3 Bucket for Static Website (to display skill statistics)
  StaticWebsiteBucket:
    Type: AWS::S3::Bucket
    Properties:
      BucketName: skill-ws-cartagena
      PublicAccessBlockConfiguration:
        BlockPublicAcls: false
        BlockPublicPolicy: false
        IgnorePublicAcls: false
        RestrictPublicBuckets: false      
      WebsiteConfiguration:
        IndexDocument: index.html

  # DynamoDB BD for Skill Data
  SkillDataBase:
    Type: AWS::DynamoDB::Table
    Properties:
          TableName: "user-skills"  # Specify the name of your DynamoDB table
          AttributeDefinitions:
            - AttributeName: "uuid"    # Primary key attribute
              AttributeType: "S"       # 'S' for String
            - AttributeName: "skill" # Attribute for Global Secondary Index (GSI)
              AttributeType: "S"
          KeySchema:
            - AttributeName: "uuid"    # Partition key (primary key)
              KeyType: "HASH"          # HASH specifies that it's the partition key
          GlobalSecondaryIndexes:      # Define a GSI for the 'company' attribute
            - IndexName: "SkillIndex"
              KeySchema:
                - AttributeName: "skill"  # Use 'skill' as the key for the GSI
                  KeyType: "HASH"
              Projection:
                ProjectionType: "ALL"   # You can specify 'KEYS_ONLY', 'INCLUDE', or 'ALL'
          BillingMode: PAY_PER_REQUEST   # On-Demand mode, suitable for the free tier


  # Static Website Content Policy
  StaticWebsiteBucketPolicy:
    Type: AWS::S3::BucketPolicy
    Properties:
      Bucket: skill-ws-cartagena
      PolicyDocument:
        Statement:
          - Effect: Allow
            Action: s3:GetObject
            Resource: "arn:aws:s3:::skill-ws-cartagena/*"
            Principal: "*"


  # Lambda Execution Role
  LambdaExecutionRole:
    Type: AWS::IAM::Role
    Properties:
      AssumeRolePolicyDocument:
        Version: "2012-10-17"
        Statement:
          - Effect: Allow
            Principal:
              Service: lambda.amazonaws.com
            Action: sts:AssumeRole
      Policies:
        - PolicyName: LambdaPolicy
          PolicyDocument:
            Version: "2012-10-17"
            Statement:
              - Effect: Allow
                Action:
                  - dynamodb:PutItem
                  - s3:GetObject
                  - logs:CreateLogGroup
                  - logs:CreateLogStream
                  - logs:PutLogEvents
                Resource: "*"

  # CloudWatch Log Group for Lambda
  LambdaLogGroup:
    Type: AWS::Logs::LogGroup
    Properties:
      LogGroupName: ProcessExcelLambda # Created by console in CloudWatch
      RetentionInDays: 5

  # Lambda Function to process Excel and store in DynamoDB
  ProcessExcelLambda:
    Type: AWS::Lambda::Function
    Properties:
      FunctionName: ProcessExcelLambda
      Handler: lambda_function.lambda_handler
      Role: LambdaExecutionRole # Created by console in Roles
      Code:
        ZipFile: |
          import json
          import boto3
          import pandas as pd
          import io

          s3 = boto3.client('s3')
          dynamodb = boto3.resource('dynamodb')
          table = dynamodb.Table('SkillDataTable')

          def lambda_handler(event, context):
              # Get the bucket and file key from the S3 event
              bucket = event['Records'][0]['s3']['bucket']['name']
              key = event['Records'][0]['s3']['object']['key']

              # Download the file from S3
              response = s3.get_object(Bucket=bucket, Key=key)
              content = response['Body'].read()

              # Read the Excel file
              df = pd.read_excel(io.BytesIO(content))

              # Iterate over rows and put them in DynamoDB
              for index, row in df.iterrows():
                  table.put_item(
                      Item={
                          'name': row['name'],
                          'company': row['company'],
                          'skill': row['skill'],
                          'level': int(row['level'])
                      }
                  )
              return {
                  'statusCode': 200,
                  'body': json.dumps('File processed and data saved!')
              }

      Runtime: python3.9
      Timeout: 30
      MemorySize: 128
      Events:
        S3UploadEvent:
          Type: S3
          Properties:
            Bucket: ExcelUpCartagena
            Events: s3:ObjectCreated:*                
